spring.application.name=spring-langchain4j-structured-output

langchain4j.ollama.chat-model.base-url=http://localhost:11434
langchain4j.ollama.chat-model.model-name=gemma3:4b
langchain4j.ollama.chat-model.log-requests=true
langchain4j.ollama.chat-model.log-responses=true
langchain4j.ollama.chat-model.timeout=120s
langchain4j.ollama.chat-model.supported-capabilities=response_format_json_schema

logging.level.de.gedoplan.showcase.langchain4jdemo=DEBUG
logging.level.dev.langchain4j=DEBUG